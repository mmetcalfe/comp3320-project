% !TEX TS-program = pdflatex
% !TEX encoding = UTF-8 Unicode

% This is a simple template for a LaTeX document using the "article" class.
% See "book", "report", "letter" for other types of document.

\documentclass[11pt]{scrartcl} % use larger type; default would be 10pt

\usepackage[utf8]{inputenc} % set input encoding (not needed with XeLaTeX)
\usepackage[title,titletoc,header]{appendix}
\usepackage{multicol}
% \usepackage{titling}
\usepackage{longtable}

\usepackage{amsmath}
\usepackage{hyperref}

%%% Examples of Article customizations
% These packages are optional, depending whether you want the features they provide.
% See the LaTeX Companion or other references for full information.

%%% PAGE DIMENSIONS
\usepackage[a4paper]{geometry} % to change the page dimensions
% \geometry{a4paper, margin=1.3in} % or letterpaper (US) or a5paper or....
% \geometry{margin=2in} % for example, change the margins to 2 inches all round
% \geometry{landscape} % set up the page for landscape
%   read geometry.pdf for detailed page layout information

\usepackage{graphicx} % support the \includegraphics command and options

% \usepackage[parfill]{parskip} % Activate to begin paragraphs with an empty line rather than an indent

%%% PACKAGES
\usepackage{booktabs} % for much better looking tables
\usepackage{array} % for better arrays (eg matrices) in maths
\usepackage{paralist} % very flexible & customisable lists (eg. enumerate/itemize, etc.)
\usepackage{verbatim} % adds environment for commenting out blocks of text & for better verbatim
\usepackage{subfig} % make it possible to include more than one captioned figure/table in a single float
% These packages are all incorporated in the memoir class to one degree or another...

\usepackage{pgfgantt} % gantt charts
% \usepackage[export]{adjustbox}[2011/08/13] % For centering wide figures

%%% HEADERS & FOOTERS
\usepackage{fancyhdr} % This should be set AFTER setting up the page geometry
\pagestyle{fancy} % options: empty , plain , fancy
\renewcommand{\headrulewidth}{0pt} % customise the layout...
\lhead{}\chead{}\rhead{}
\lfoot{}\cfoot{\thepage}\rfoot{}

%%% SECTION TITLE APPEARANCE
\usepackage{sectsty}
\allsectionsfont{\sffamily\mdseries\upshape} % (See the fntguide.pdf for font help)
% (This matches ConTeXt defaults)

%%% ToC (table of contents) APPEARANCE
\usepackage[nottoc,notlof,notlot]{tocbibind} % Put the bibliography in the ToC
\usepackage[titles,subfigure]{tocloft} % Alter the style of the Table of Contents
\renewcommand{\cftsecfont}{\rmfamily\mdseries\upshape}
\renewcommand{\cftsecpagefont}{\rmfamily\mdseries\upshape} % No bold!


\newcommand{\code}[1]{{\texttt{#1}}}
\newcommand{\libraryname}[1]{{\texttt{#1}}}
\newcommand{\codefile}[1]{{\textit{#1}}}
\newcommand{\program}[1]{\code{#1}}
\newcommand{\taskname}[1]{{\textit{#1}}}

%%% END Article customizations

% \setlength{\parindent}{0pt}
% \setlength{\parskip}{2ex plus 0.5ex minus 0.3ex}

%%% The "real" document content comes below...

% TODO: Catchy project title
\title{Graphics Project Final Report}
\subtitle{Game-engine demonstration via a dynamic space-themed environment}
% \subtitle{A 3D testing environment for an enhanced virtual reality system}
\author{ Mitchell Metcalfe, James Ross-Gowan }

\date{\today} % Activate to display a given date or no date (if empty),
            % otherwise the current date is printed
\rhead{ COMP3320, Final Report, \today }

\begin{document}
% \newgeometry{top=2cm}
\maketitle
% \vspace{-1.5 cm}
% \restoregeometry

\begin{abstract}

    % Indicate that the project is a game engine targeted at high-quality visualisations.

    This report summarises the final result of our graphics project to create a
    game engine targeted at high-quality visualisations.  We describe the
    demonstration scene diplayed in our project presentation, and discuss the
    features and effects implemented in our game-engine, and the techniques
    used to achieve them. Additionally, we discuss the performance of our game
    engine, compare it to a popular commercial game engine, and outline areas
    of focus for future work.

\end{abstract}

\newpage

\tableofcontents

\newpage

% So far the report seems to be mainly about project management.
% For the final reprot it would be good to have:
% -- Description of th system
% -- Structure of the system
% -- Details about performance evaluation. Where are the bottlenecks?
% -- What is the most interesting part of your project? Where did you put the emphasis?
% -- How does your project compare to similar existing implementations?
% -- What would be the next steps if there would be more time?

\section{Project Goals}

    Our initial project proposal indicated that we would create a 3D engine
    using OpenGL and a test scene geared towards creating an immersive virtual
    reality system. Due to time constraints, changes in the structure of our
    team, and an unexpected lack of access to VR equipment, we chose to shift
    our focus to creating a 3D game engine that would support visually
    impressive graphics. The test scene we have created is similar to the scene
    described in our initial proposal, except that we have optimised for visual
    quality, rather than the high frame-rate and low latency that a VR
    application would demand.


\section{Final Submission}

    Our final project submission and demonstration consists of our OpenGL game
    engine code, and a space scene that has been constructed to showcase the
    many features of our game engine. The scene consists of a circular room
    suspended in space, with a large glass tube containing a moving, reflective
    sphere at its centre. The room has four curved, elliptic, glass windows
    equally spaced around its circumference. A complicated spaceship model
    (sourced from
%
    \url{http://www.cgtrader.com/free-3d-models/space/spacecraft-sci-fi/eagle-5-transport})
%
    has been placed outside the room, opposite one
    of the windows. The room is illuminated by three spotlights, placed on the
    ceiling and inside the glass tube, and by sunlight from outside. The room
    contains a reflective metal robot with two forward-facing spotlights, that
    moves around the floor. A number of procedurally generated asteroids orbit
    the circular room. The scene has a background of stars and nebulae. Figure~\ref{fig:scene-overview}
    and Figure~\ref{fig:robot-closeups} show the scene and the robot respectively.

    \begin{figure}%[H]
        \centering
        \includegraphics[width=0.4\textwidth]{room-overview.png}
        \includegraphics[width=0.4\textwidth]{scene-overview.png}
        \caption[Demonstration scene]{
            Two screenshots of the demonstration scene.
        }
        \label{fig:scene-overview}
    \end{figure}

    \begin{figure}%[H]
        \centering
        \includegraphics[width=0.3\textwidth]{robot-1.png}
        \includegraphics[width=0.3\textwidth]{robot-2.png}
        \includegraphics[width=0.3\textwidth]{robot-3.png}
        \caption[Space-room exterior]{
            Close-up views of the robot
        }
        \label{fig:robot-closeups}
    \end{figure}

    The following subsection describes the features and techniques that were
    used to create the test scene.

    \subsection{Features Implemented}

        \subsubsection{Load 3D model files}

            The \libraryname{Assimp} library was used to load 3D model and
            material data from model files.

        \subsubsection{Textures}

            Our engine can render both textured and untextured meshes.

            The texture image filenames for textured materials are loaded by
            \libraryname{Assimp}, and then \libraryname{libjpg} or
            \libraryname{libpng} is used to load the image data before
            supplying it to OpenGL.

            Untextured meshes are supported by rendering the entire mesh in a
            single colour.
            A model can contain both textured and untextured meshes, as shown in the screenshot of the textured spaceship model in Figure~\ref{fig:ship-textures}.

            \begin{figure}%[H]
                \centering
                % \makebox[\textwidth][c]{\resizebox{0.95\paperwidth}{!}{\input{module2_gantt.tex}}}
                \includegraphics[width=0.5\textwidth]{ship-textures.png}
                \caption[Textured spaceship]{
                    The textured spaceship model (from
                    \url{http://www.cgtrader.com/free-3d-models/space/spacecraft-sci-fi/eagle-5-transport}).
                }
                \label{fig:ship-textures}
            \end{figure}

        \subsubsection{Bump mapping}

            Our engine supports bump map textures that are used to perturb
            normals during shading to simulate the interaction of lighting with
            fine surface details.

            A bump map is used to render the floor stubs on the floor of the
            spaceship in the demonstration scene, as shown in Figure~\ref{fig:bump-mapping}.

            \begin{figure}%[H]
                \centering
                \includegraphics[width=0.5\textwidth]{bump-mapping-1.png}
                \\
                \includegraphics[width=0.3\textwidth]{robot-normals-a.png}
                \includegraphics[width=0.3\textwidth]{robot-normals-n.png}
                \includegraphics[width=0.3\textwidth]{robot-normals-f.png}
                \caption[Textured spaceship]{
                    Top: Close-up of the bump-mapped floor and robot.
                    Bottom: Albedo component, view-space normals, and final render of the bump-mapped robot and floor. Note that the albedo compoent has no texturing.
                }
                \label{fig:bump-mapping}
            \end{figure}

        \subsubsection{Skybox rendering}

            A cube map is used to render a skybox. This gives the scene a
            plausible backdrop, increasing realism.

        \subsubsection{Environment mapped reflections}

            Each object can be assigned a cubemap texture to be used as an
            environment map for simulating reflections.
            Figure~\ref{fig:reflection} illustrates the reflections on the robot in the demonstration scene.

            \begin{figure}%[H]
                \centering
                \includegraphics[width=0.5\textwidth]{reflection.png}
                \\
                \includegraphics[width=0.4\textwidth]{deferred-robot-f.png}
                \includegraphics[width=0.4\textwidth]{deferred-robot-r.png}
                \caption[Textured spaceship]{
                    Top: The robot reflecting a window and the asteroid in the tube.
                    Bottom: An image of the robot, and the contribution to that image from reflections alone.
                }
                \label{fig:reflection}
            \end{figure}

        \subsubsection{Filtered shadow maps}

            Shadow mapping is used to render shadows. Both spotlights and
            directional lights can use shadow maps. Spotlight shadows are not
            supported (as their implementation is more time-consuming).

            When determining the lighting contribution based on a shadow map,
            we sample the shadow map at multiple random points uniformly
            distributed around the actual shadow map coordinate for the point.
            The lighting contribution for the pixel is multiplied by the
            fraction of the sample points that were not in shadow. This has the
            effect of smoothing the edges of the shadows - removing the obvious
            jagged edges that result from limited shadow map resolution.

            Figure~\ref{fig:shadow-maps} shows the shadow maps rendered for the demonstration scene.

            \begin{figure}%[H]
                \centering
                \includegraphics[width=0.3\textwidth]{shadow-map-3.png}
                \includegraphics[width=0.3\textwidth]{shadow-map-2.png}
                \includegraphics[width=0.3\textwidth]{shadow-map-4.png}
                \includegraphics[width=0.3\textwidth]{shadow-map-5.png}
                \includegraphics[width=0.3\textwidth]{shadow-map-7.png}
                \includegraphics[width=0.3\textwidth]{shadow-map-6.png}
                \includegraphics[width=0.3\textwidth]{shadow-map-1.png}
                \caption[Deferred rendering buffers]{
                    Sample shadow maps of the 7 lights in the demonstration scene.
                }
                \label{fig:shadow-maps}
            \end{figure}

        \subsubsection{Forward and deferred rendering}

            To support multiple lights efficiently, we implemented a deferred
            renderer in addition to a forward renderer. When performing
            deferred rendering, we first render the eye-space normals, albedo,
            roughness, environment map reflection term, emissive flag, metallic
            flag, and depth to a set of framebuffers (collectively referred to
            as the `Geometry Buffer' or `G-Buffer'). These buffers are used as
            inputs to another shader which is used to add the contribution of
            each light to the screen in multiple additional render passes.
            The main components of the g-buffer for a sample frame can be seen in Figure~\ref{fig:deferred-rendering}.

            \begin{figure}%[H]
                \centering
                \includegraphics[width=0.3\textwidth]{deferred-1-a.png}
                \includegraphics[width=0.3\textwidth]{deferred-1-n.png}
                \includegraphics[width=0.3\textwidth]{deferred-1-r.png}
                \includegraphics[width=0.3\textwidth]{deferred-1-d.png}
                \includegraphics[width=0.3\textwidth]{deferred-1-f.png}
                \includegraphics[width=0.3\textwidth]{deferred-1-forward.png}
                \caption[Deferred rendering buffers]{
                    The deferred rendering path. From top left to bottom right:
                    The albedo buffer;
                    View-space normals;
                    Environment map reflection buffer;
                    Depth buffer;
                    The final image;
                    and an example of the simplified forward rendering path that
                    is used to render the dynamic environment map.
                }
                \label{fig:deferred-rendering}
            \end{figure}

            The common optimisation of rendering `light volumes' to the stencil
            buffer before rendering lighting contributions was not implemented
            due to time constraints. As a result, several lights must be
            present in the scene before our deferred shading implementation
            exhibits a clear speed advantage.

        \subsubsection{Multiple lights}

            Both our forward and deferred shading implementations support an
            arbitrary number of lights in the scene. Multple lights are
            supported by simply rendering the contribution of each light to a
            temporary framebuffer before adding that framebuffer to the screen
            in turn.

        \subsection{Light types}

            Our engine supports three types of lights:

            \begin{itemize}

            \item[Point lights:]

                Simple point lights that emit light in all directions. These do
                not cast shadows.

            \item[Spotlights:]

                Spotlights that emit a cone of light in a given direction.
                These cast shadows and have an adjustable `inner angle', which
                allows the light emitted to be more intense at the centre of
                the cone, and fall off towards the edges.

            \item[Directional lights:]

                Defines a square region that emits light with a constant
                direction vector - as if a light source at infinity were
                shining through a square window. These cast shadows by using an
                orthographic projection to render the shadow map. A directional
                light is used to simulate sunlight in our demonstration scene, as seen in Figure~\ref{fig:directional-light}.

                \begin{figure}%[H]
                    \centering
                    \includegraphics[width=0.4\textwidth]{directional-1.png}
                    \includegraphics[width=0.4\textwidth]{directional-2.png}
                    \caption[Directional lights]{
                        Two views of the shadows cast by the directional light.
                    }
                    \label{fig:directional-light}
                \end{figure}

            \end{itemize}

        \subsubsection{Dynamic reflection mapping}

            Our engine allows dynamic reflections on a per-object basis. If
            dynamic reflections are enabled for a given object, an environment
            map is rendered for that object centred at the object's origin.
            This environment map is then used to calculate the reflection term
            when shading the object.

            Environment maps are rendered using the forward shading
            implementation. All objects other than the given reflective object
            are rendered to the environment map.

            Rendering dynamic reflection maps is very slow, but significantly
            improves the realism of reflections.

        \subsubsection{Procedurally generated asteroids}

            The asteroids in the test scene are procedurally generated and
            placed.

            The mesh of each asteroid is generated by recursively subdividing
            the faces of an icosahedron, while randomly perturbing the distance
            from the icosahedron's center of each new point.

            One of the asteroids in the demonstration scene is pictured in Figure~\ref{fig:asteroid}.

            \begin{figure}%[H]
                \centering
                \includegraphics[width=0.5\textwidth]{asteroid.png}
                \caption[Asteroid]{
                    A closeup view of the tube-asteroid.
                }
                \label{fig:asteroid}
            \end{figure}

        \subsubsection{Phong lighting}

            The Phong lighting formula is used to calculate the lighting
            contribution from each light at each screen pixel. Each material
            has a configurable `shininess' parameter.

        \subsubsection{Fresnel effect for specular and environment reflections}

            An additional term is used in the lighting calculation to simulate
            the `Fresnel effect', where light appears more intense when
            reflected at glancing angles. This more accurately simulates
            lighting on many glossy surfaces.

        \subsubsection{Transparent materials}

            Transparency (or, more accurately, `dissolve') is supported as a
            material property. Transparent materials are only rendered using
            the deferred shading implementation. To render transparent
            materials, all fully opaque materials are first rendered to the
            g-buffer. Then, depth writes are disabled, and for each transparent
            mesh, the mesh is rendered to a framebuffer using the depth buffer
            from the g-buffer, before adding that framebuffer to the screen
            multiplied by the opacity of the material. The result is order-
            independent transparency that looks reasonable.
            An example screenshot is included as Figure~\ref{fig:transparent}.

            \begin{figure}%[H]
                \centering
                \includegraphics[width=0.5\textwidth]{transparency.png}
                \caption[Transparent materials]{
                    A screenshot showing models viewed through several layers of glass.
                }
                \label{fig:transparent}
            \end{figure}

        \subsubsection{Emissive materials}

            Simple emissive materials are implemented by treating the diffuse
            colour of the material as the emissive colour. The light-globes of
            the robot in the demonstration scene are a white emissive material.

        \subsubsection{Metallic materials}

            A modified lighting calculation has been implemented to support
            metallic materials. This material type simulates a shiny metal by
            multiplying the diffuse colour by the environment map reflection
            when calculating environment map reflections. The result is the
            appearence of a shiny metal rather than a glossy plastic surface.
            This material is applied to the robot in the demonstration scene.


\section{Implementation details}

    % Languages used:

    The game engine is implemented in \libraryname{C++}, and uses a
    \libraryname{CMake} build system.

    % List libraries used + purposes:

    The \libraryname{GLFW} library was used for \libraryname{OpenGL} context
    creation, and to provide keyboard and mouse input.
%
    \libraryname{Assimp} was used to support loading 3D models from a variety
    of file formats (only the \codefile{OBJ} and \codefile{MTL} formats were
    actually used in the final project).
%
    The libraries \libraryname{libpng} and \libraryname{libjpg} were used to
    load textures (as \libraryname{Assimp} only provides the file names of
    textures used in each material).

    % Tools used:

    Most of the development work was done using the \libraryname{CLion} IDE.
    %
    \libraryname{Blender} was used to create the custom 3D models that appear
    in the demonstration scene.


\section{Code structure}

    The code is organised into three main namespaces:

    \begin{description}

        \item[\codefile{NUGL}:]

            Contains an object-oriented wrapper around the raw OpenGL C API.
            Most interaction with OpenGL is done through the objects in this
            namespace.

            Most of these wrapper classes are fairly minimal, except that the
            Texture class contains helper functions for creating and loading
            various kinds of textures, and the ShaderProgram class is aware of
            the materials system, and can report which of a number of
            application defined uniforms the shader program supports.

        \item[\codefile{scene}:]

            Contains classes that together provide the means to describe and render a scene.

            A brief outline of classes in this namespace is provided below.

            \begin{description}

                \item[\codefile{Camera}:]

                    Represents a camera with a position and an orientation in
                    world space, and provides methods to obtain the \code{view}
                    and \code{proj} matrices Both perspective and orthogonal
                    cameras are supported. The LightCamera subclass provides a
                    function to create a camera from a light specifically for
                    rendering shadow maps, and the PlayerCamera subclass
                    provides methods to support camera movement using the mouse
                    and keyboard.

                \item[\codefile{Light}:]

                    A struct that contains all information necessary to
                    represent any of the three supported light types. Helper
                    methods exist to create lights with default settings
                    easily.

                \item[\codefile{Material}:]

                    A struct containing the parameters and textures that define a material.

                \item[\codefile{Mesh}:]

                    Represents a component of a model, with its own material,
                    and vertex and element buffers. Provides methods for
                    rendering the component.

                \item[\codefile{Model}:]

                    Represents an entire model that might be loaded from a
                    file, and placed within the scene. Modelled after the
                    representation that \libraryname{Assimp} uses, the model is
                    represented as a hierarchy of nodes, each containing
                    meshes, a transform relative to its parent, and child
                    nodes. Models can also contain lights (like the robot in
                    the demonstration scene).
                    Methods are provided to load and render models.

                \item[\codefile{ProceduralAsteroid}:]

                    Provides methods to procedurally generate asteroid models.

                \item[\codefile{Scene}:]

                    Represents an entire scene as a collection of Models, and a
                    dedicated skybox model. Provides the main rendering
                    methods, that accumulate lighting passes and write to the
                    default framebuffer. Both forward and deferred rendering
                    paths are supported.

            \end{description}

        \item[\codefile{utility}:]

            Contains a variety of utility functions and classes related to
            maths, string handling, profiling, debugging, memory
            management, and rendering.

    \end{description}

    The entry point of the program is found in program.cpp - the only file
    containing code in the default namespace. This file contains code to create
    the OpenGL context, load and set up the demonstration scene, run the main
    program loop, update the positions of moving objects, and to handle basic
    keyboard controls.

\section{Performance evaluation}

    A profiler class was created to to aid in optimising parts of the engine
    during development. To measure the runtime of various operations within the
    OpenGL driver, the profiler code has to call \code{glFinish} to synchronise
    the CPU and the GPU to ensure that the work it is trying to measure the
    runtime of has been completed. For this reason, while the times the
    profiler outputs are useful in estimating the relative runtimes of
    different parts of the program, the times shown are not representitive of
    the actual runtimes while not profiling. The code is typically close to
    twice as fast when not profiling, as the OpenGL driver is able to run parts
    of the program in parallel (and there is less synchronisation overhead).

    Below is some typical output of the built-in profiler when rendering the
    room scene at $1920*1080$ pixels on an early 2013 MacBook Pro running OS X
    10.9.5, with a 2.7 GHz Intel Core i7 processor, 16 GB of 1600 MHz DDR3
    system memory, and an NVIDIA GeForce GT 650M graphics card with 1024 MB of
    graphics memory:

    {
        \small
        \input{profiler_output.tex}
    }

    %  - Dynamic reflections (+ simplified geometry/shaders)

    From the profiler output, we can see that 28.4\% of the time taken to
    render each frame is used in rendering the (single) dynamic reflection map.
    Only one face of the dynamic reflection cube map is rendered each frame.
    Time could be saved here by using simplified scene geometry when rendering
    reflections.

    % - Render shadow maps once per frame

    We can see that the shadow map for each light is rendered once while
    rendering to the reflection map, and again before the deferred shading
    pass. Time could be saved here by storing all shadow maps in separate
    textures and rendering them once at the start of each frame.

    %  - Light bounding volumes for deferred shading

    The profiler output shows that 45.24\% of the rendering time is spent on
    the deferred lighting passes. This time could be significantly reduced by
    using the common optimisation of rendering the bounding volumes of each
    light's area of effect to the stencil buffer before rendering the light, to
    ensure that only pixels that could be influenced by the light are processed
    by the pixel shader.

    %  - Mipmapping

    None of the textures used in the engine have had mipmaps created for them.
    Generating mipmaps and enabling mipmapping would have the potential to
    speed up all rendering code that samples from textures.

    Additional optimisations would be to reduce the number of matrix multiplies
    in the shader programs (some of them can be trivially precalculated), and
    to reduce the number of draw calls by implementing basic visibility testing
    of entire meshes or models.

% -- How does your project compare to similar existing implementations?
\section{Comparison to existing engines}

    In this section we will briefly compare my engine to an existing game
    engine, to highlight which features they share. The engine chosen for this
    comparison is Unreal Engine 4 (see \url{www.unrealengine.com}), a modern
    top-tier, professional game engine. Specifically, we will compare the
    rendering engines of the two game engine, particularly features relating to
    materials, reflections and lighting, as these were our areas of focus.

    \subsection{Materials}

        Both our engine and the Unreal engine support the following material properties:

        \begin{itemize}
            \item A base colour;
            \item Metallic;
            \item Roughness;
            \item Opacity;
            \item Emissive;
            \item Diffuse colour texturing;
            \item Bump mapping;
            \item Reflections;
        \end{itemize}

        The Unreal engine provides several more options for some of these
        properties. For example, while our engine's metallic value is boolean,
        Unreal engine accepts a \code{float} indicating how metallic the
        material appears.

        The Unreal engine's material system supports a number of additional
        features including:

        \begin{itemize}
            \item True translucent materials, whose specular highlights appear at full brightness;
            \item Refraction through transparent materials;
            \item Tesselation;
            \item Glossy reflections;
        \end{itemize}

    \subsection{Lighting}

        Both our engine and Unreal Engine 4 support the following types of
        dynamic light:

        \begin{itemize}
            \item Point light;
            \item Spot light with cone falloff;
            \item Directional light;
        \end{itemize}

        With regard to these basic light types, Unreal Engine supports shadows
        for all three types of light, whereas our engine supports shadows for
        spot lights and directional lights, but not for point lights.

        Unreal engine supports many additional lighting features, including:

        \begin{itemize}
            \item Indirect lighting via lightmaps for static objects, and a global illumination cache for dynamic objects;
            \item Illuminating Engineering Society (IES) light profiles;
        \end{itemize}

    \subsection{Reflections}

        Both our engine and Unreal Engine 4 support reflection of environment
        maps and reflection using dynamically rendered cube maps.

        Unreal engine supports several other reflection methods and many
        reflection parameters. Notably, it supports static reflection maps that
        are rendered at load time (a feature that our engine could be made to
        support with little effort), and screenspace raytraced reflections.

% -- What would be the next steps if there would be more time?
\section{Future work}

    The following lists outline areas of focus for improvement of the game
    engine if more development time were available. We distinguish between
    improvements to current features, and new features that could be
    introduced.

    \paragraph{Minor improvements:}
    \begin{itemize}
        \item Render environment map only once in forward shading pipeline;
        \item Profile application (optimise shaders, uniforms, etc.);
        \item Implement light bounding volumes to speed up deferred shading;
    \end{itemize}

    \paragraph{Potential new features:}
    \begin{itemize}
        \item HDR rendering;
        \item Bloom lighting;
        \item Displacement mapping;
        \item Screen-space ambient occlusion;
        \item Screen-space ray-traced reflections;
        \item Physically based soft shadows;
    \end{itemize}

% -- What is the most interesting part of your project? Where did you put the emphasis?

\section{Conclusion}

    In summary, we created an OpenGL game-engine that supports many features
    present in high-end game-engines. We demonstrated the features of our
    engine by rendering a complex, dynamic, space-themed scene in real-time.


\end{document}

